{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8079ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7b95261b3a10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "from llama2 import Llama2Model\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560a723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KVCache:\n",
    "  def __init__(self, n_layers):\n",
    "    self.cache = [None] * n_layers\n",
    "\n",
    "  def get(self, layer_idx):\n",
    "    return self.cache[layer_idx]\n",
    "\n",
    "  def update(self, layer_idx, value):\n",
    "    self.cache[layer_idx] = value\n",
    "\n",
    "  def get_all(self):\n",
    "    return self.cache \n",
    "\n",
    "  def reset(self):\n",
    "    for i in range(len(self.cache)):\n",
    "      self.cache[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f545e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA2_CONFIG_7B = {\n",
    "    \"vocab_size\": 32000,     # Vocabulary size\n",
    "    \"ctx_len\": 4096,         # Context length\n",
    "    \"d_model\": 4096,         # Embedding dimension\n",
    "    \"n_heads\": 32,           # Number of attention heads\n",
    "    \"n_layers\": 32,          # Number of layers\n",
    "    \"d_ff\": 11008,           # NEW: Size of the intermediate dimension in FeedForward\n",
    "    # \"dtype\": torch.bfloat16  # NEW: Lower-precision dtype to reduce memory usage\n",
    "}\n",
    "\n",
    "model = Llama2Model(LLAMA2_CONFIG_7B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96f8470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = [0, 1, 2, 3, 4]\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "encoded_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5b2c2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1468,  0.9266,  0.4884,  ..., -0.1634, -1.3636, -0.1411],\n",
       "         [-0.0795,  1.5225,  0.2883,  ..., -0.3145, -1.2785,  0.2247],\n",
       "         [-0.3107,  1.0335,  0.7911,  ..., -0.9444, -1.0664, -0.6065],\n",
       "         [-0.5140,  0.8891,  0.5288,  ..., -0.8170, -0.0885,  0.7101],\n",
       "         [-0.1581,  0.6680,  0.3907,  ..., -0.6547, -0.8114,  0.3739]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(encoded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beda4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, ctx_len, use_cache=True):\n",
    "  \"\"\"\n",
    "  idx: (batch_size, seq_len)\n",
    "  \"\"\"\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    if use_cache:\n",
    "      cache = KVCache(model.cfg[\"n_layers\"])\n",
    "      model.reset_kv_cache()\n",
    "      logits = model(idx[:,-ctx_len:], cache=cache)\n",
    "      for _ in range(max_new_tokens):\n",
    "        next_idx = logits[:,-1,:].argmax(dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, next_idx), dim=1)\n",
    "        logits = model(next_idx, cache=cache)\n",
    "    else:\n",
    "      for _ in range(max_new_tokens):\n",
    "        logits = model(idx[:,-ctx_len:], cache=None)\n",
    "        next_idx = logits[:,-1,:].argmax(dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, next_idx), dim=1)\n",
    "\n",
    "  return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6d728b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     2,     3,     4, 16062, 17784,  6099,  3964, 24148,\n",
       "          6537, 12469, 23455, 14386, 13850]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text_simple(model, encoded_tensor, 10, 4096, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348d3680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     2,     3,     4, 16062, 17784,  6099,  3964, 24148,\n",
       "          6537, 12469, 23455, 14386, 13850]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text_simple(model, encoded_tensor, 10, 4096, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b71dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
